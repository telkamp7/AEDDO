\chapter{Simulation study}

In this chapter, a simulation study is conducted to evaluate the performance of the novel outbreak detection algorithm compared to state-of-the-art algorithms. The simulations cover various scenarios, adapted from the study by @Noufaily_2013. 

The chapter begins by describing the method used to simulate the baseline data. These data are generated using a Negative Binomial model with a time-dependent mean $\mu(t)$. Next, the assumptions regarding the simulated outbreaks are outlined, including the outbreak size and distribution in time.

The evaluation measures used to assess the performance of the outbreak detection algorithms are then presented. These measures are designed to capture relevant quantities in the context of outbreak detection.

Finally, the chapter presents the results of applying both the state-of-the-art and the novel outbreak detection algorithms to the simulated data. The performance of both algorithms is evaluated based on the simulation results.

\section{The simulated baseline data}

The simulated baseline data is generated using a Negative Binomial model with a mean parameter $\mu$ and a variance parameter $\phi\mu$. The dispersion parameter $\phi$ is assumed to be greater than or equal to 1. The mean $\mu(t)$ is defined by a linear predictor that includes a trend component and a seasonality component represented by Fourier terms.

The equation for $\mu(t)$ is given as:

\begin{equation}
\mu(t)=\exp\Biggl(\theta+\beta_t+\sum_{j=1}^m \biggl(\gamma_1 \cos\Bigl(\frac{2\pi jt}{52}\Bigl) + \gamma_2 \sin \Bigl(\frac{2\pi jt}{52} \Bigl)\biggl)\Biggl)
\end{equation}

In this equation, $m$ represents the number of Fourier terms used to model seasonality. When $m=0$, it indicates the absence of seasonality, while $m=1$ corresponds to annual seasonality.

To cover a wide range of data sets encountered in practical applications, 28 different parameter combinations are generated. These combinations vary in terms of trends (represented by different values of $\beta$), seasonalities (represented by different values of $\gamma_1$ and $\gamma_2$), baseline frequencies of reports (represented by different values of $\theta$), and dispersion (represented by different values of $\phi$). The specific parameter values for the 28 scenarios are provided in Table \@ref(tab:scenariosTbl).

\newpage

```{r scenariosTbl, echo=FALSE}

scenarios %>%
  mutate(Scenario = row_number()) %>%
  select(Scenario, theta, phi, beta, gamma1, gamma2, m, trend) %>%
  rename(`$\\theta$` = theta, `$\\beta$` = beta, `$m$` = m, `$\\phi$` = phi, `$\\gamma_1$` = gamma1, `$\\gamma_2$` = gamma2, Trend = trend) %>%
  kbl(booktabs = TRUE, escape = FALSE, align = "l", longtable = TRUE, caption = "Parameters and criteria utilized to generate the 28 scenarios.",
      linesep = c(rep("", 3), "\\addlinespace")) %>%
  kable_paper(latex_options = c("repeat_header", "HOLD_position"), repeat_header_method = c("replace"))

```


To simulate the baseline data without outbreaks, 100 replicates are generated for each of the 28 parameter scenarios. Each replicate consist of a time series of size $T=624$ weeks. 

The 624 weeks are divided into three periods: weeks 1-313 are used for training, weeks 313-575 are considered as baseline weeks, and weeks 576-624 are designated as the test weeks for evaluation. 

The simulation results are based on the test weeks of all the replicates, totaling $100\times 49=4900$ weeks, for each of the 28 data scenarios and each method investigated.

\section{The simulated outbreaks}

The outbreaks starting in week $t_i$ are simulated using the following procedure. First, a constant value $k$ is chosen at random. The size of the outbreak, denoted as $v$, is then generated randomly from a Poisson distribution with a mean equal to $k$ times the standard deviation of the baseline count in that scenario.

Next, the outbreak is distributed randomly in time according to a discretized log-normal distribution with a mean of $0$ and a standard deviation of $0.5$, represented as $Z \sim \lfloor \LN(0,0.5^2)\rfloor$. This is achieved by drawing $v$ random numbers, which correspond to the outbreak size, from the specified log-normal distribution and then rounding down these numbers to the nearest integer.

The probability mass function for the discretized log-normal distribution is visualized in Figure \@ref(fig:PDFLogNormal).

(ref:PDFLogNormal) Stairstep plot of the probability mass function for the discretized log-normal distribution with a mean of 0 and a standard deviation of 0.5, i.e. $Z \sim \lfloor \LN(0,0.5^2)\rfloor$.

```{r PDFLogNormal, echo=FALSE, out.width="100%", fig.cap="(ref:PDFLogNormal)", fig.pos = "H", fig.show = "hold"}

knitr::include_graphics("../figures/PDFLogNormal.png")

```

Typically, outbreak durations of 2-4 weeks are observed when values of $k$ are in the range of 2-10. To simulate the outbreaks, the outbreak cases are added to the baseline count in week $t_i+z_i$, where $t_i$ represents the start time of the outbreak and $z_i$ represents the number of weeks after the start of the outbreak. The start and end times of the outbreaks are recorded for evaluating the performance of the methods.

To simulate outbreaks, the following procedure is followed:

\begin{itemize} 
\item \textbf{Outbreaks in baseline weeks:} For each data series, four outbreaks are generated. The start time of each outbreak is randomly selected from the baseline weeks (weeks 313-575). The value of $k$ is sampled randomly with replacement from the set $\{2, 3, 5, 10\}$. It should be noted that different outbreaks are generated for each of the 2800 runs.
\item \textbf{Outbreaks in current weeks:} For each data series, one outbreak is generated. The start time of the outbreak is randomly chosen from the last 49 weeks (weeks 576-624). The value of $k$ is sampled randomly in the range of 1 to 10. Similar to the previous case, different outbreaks are generated for each of the 2800 runs.
\end{itemize}

One randomly chosen realization for scenario 8, 12, 13, and 20 are visualized in Figure \@ref(fig:Realizations).

(ref:Realizations) Plots of one randomly chosen realization for scenario 8, 12, 13, and 20 (see Table \@ref(tab:scenariosTbl)). During outbreaks (circles), outbreak cases are added to the baseline data. Four outbreaks are added during the baseline weeks and 1 outbreak is added during the test weeks. The results are based on the data obtained in the test weeks (grey area).

```{r Realizations, echo=FALSE, out.width="100%", fig.cap="(ref:Realizations)", fig.pos = "H", fig.show = "hold"}
knitr::include_graphics("../figures/Realizations.png")
```

Evidently, the scenarios vary in their epidemiological characteristics, such as seasonality, trend, and incidence.

\section{Evaluation measures}

To evaluate the performance of the outbreak detection system in the absence and presence of outbreaks, several measures are employed to assess its effectiveness. These measures are specifically designed to capture relevant quantities in the given context.

In the absence of outbreaks in the data, one of the primary measures used is the \gls{FPR}. This is calculated for each of the 28 scenarios, before the addition of the simulated outbreaks to the baseline data. The \gls{FPR} is determined by calculating the proportion of the 49 weeks and 100 replicates in which the observed value exceeds the threshold in the absence of any simulated outbreaks.

Another measure is the \gls{POD} of an outbreak. Likewise, this is calculated for each of the 28 scenarios, but this time it is in the presence of the simulated outbreaks. The algorithm is applied iteratively for the 49 current weeks, and an outbreak is considered detected if the observed value exceeds the threshold at least once within the start and end times of the outbreak. The \gls{POD} of an outbreak is then determined as the proportion of outbreaks detected out of the 100 runs.

It is important to note that the \gls{FPR} is a rate per week, while the \gls{POD} is a rate per realization. These evaluation measures are chosen because they provide insights into the performance of the detection system on individual time series.

\section{Results of the simulations}

In this section, the results of the simulation study are presented. Both the state-of-the-art and novel outbreak detection algorithms are applied to the same simulated data, allowing for the evaluation of their performance in a setting where the true parameters and process are known. 

The data used consists of weekly counts of a simulated disease, denoted as $y_t$, where $t=1,\cdots,T$ represents the time period of $T=624$ weeks. In order to evaluate the state-of-the-art and novel outbreak detection algorithms, it is decided to include 5 years of reference data, corresponding to a total of `r 5*52` weeks.

The first step involves applying the state-of-the-art outbreak detection algorithms, with specific control arguments determined for the Farrington and Noufaily methods. These control arguments for the algorithms are specified exactly as in @Noufaily_2013, in order to reproduce the same results. Notably, the thresholds calculated in the state-of-the-art algorithms are based on the $99.5\%$ quantiles. Also, in the Noufaily method, it is decided to exclude the last $26$ weeks before the current week to avoid adaption of the model to emerging outbreaks, which would reduce its sensitivity. In the Farrington method, only $3$ weeks are excluded before the current week. To access the full configuration of the state-of-the-art methods, refer to Appendix \@ref(controlsStateOfTheArt). 

Hereafter, the novel outbreak detection algorithm is applied. For this purpose, the model for the fixed effects in each of the modeling frameworks is defined as

\begin{equation}
  \log(\lambda_{t}) = \beta_{intercept} + \beta_{trend} t + \sin \Big(\frac{2\pi\cdot \tau_t}{52}\Big) \beta_{\sin} + \cos \Big(\frac{2\pi\cdot \tau_t}{52}\Big)\beta_{\cos}
\end{equation}

Unlike the state-of-the-art algorithms, the thresholds in the novel algorithm are based on the $95\%$ quantile of the distribution of the random effects in the second stage model. This threshold is calculated based on either a Gaussian distribution using the plug-in estimate $\hat{\sigma}$ or a Gamma distribution using the plug-in estimate $\hat{\phi}$ depending on the modeling framework.

\subsubsection{False Positive Rates}

In general, the method introduced by @Farrington_1996 tends to have relatively higher \glspl{FPR} compared to the other methods. This observation is consistent with the results presented in Table \@ref(tab:FPRTbl). However, this outcome is not surprising since the Farrington method is known to be overly sensitive, making it more prone to producing false alarms. On the other hand, the improved method by @Noufaily_2013 outperforms the other methods by minimizing the \gls{FPR}.

Additionally, it is noted that the novel algorithms, using the two different modeling frameworks, perform somewhere in between the two state-of-the-art algorithms in terms of minimizing the \gls{FPR}.

```{r FPRTbl, echo=FALSE}
FPR %>%
  group_by(Method) %>%
  reframe(median(FPR), mean(FPR), sd(FPR), min(FPR), max(FPR)) %>%
  kbl(booktabs = TRUE, escape = FALSE, align = "l", caption = "Summary statstics of the \\glspl{FPR} obtained in the 28 scenarios using the four different methods.") %>%
  kable_paper(latex_option = c("HOLD_position"))
```

Upon examining Figure \@ref(fig:FPR), it becomes even more apparent that the Noufaily method consistently outperforms the other methods. Furthermore, it is interesting to note that scenario 8 and 15 consistently pose challenges for all methods, while scenarios 13-20 prove to be particularly problematic for the novel method. 

A closer look reveals that scenarios 13-20 have the highest overdispersion parameters, indicating increased variability in the data. On the other hand, scenario 8 incorporates both a steep trend and a seasonality component, which can complicate the detection process for all methods.

(ref:FPR) \glspl{FPR} obtained in each of the 28 scenarios for each of the methods applied.

```{r FPR, echo=FALSE, out.width="100%", fig.cap="(ref:FPR)", fig.pos = "H", fig.show = "hold"}

knitr::include_graphics("../figures/FPRPlot.png")

```

\subsubsection{Probability an outbreak is detected}

As expected, the \gls{POD} of an outbreak increases with the size of $k$. Intuitively, when the outbreak size $v$ is larger, it becomes more likely to be detected by the outbreak detection algorithms. In Table \@ref(tab:PODTbl), it is evident that the Farrington method performs very well in terms of \gls{POD}, closely followed by the novel method using either modeling framework. Moreover, it can be seen that the Noufaily method is outperformed by the other methods, w.r.t. \gls{POD}. 

The high performance of the Farrington method can be attributed to its sensitivity in detecting outbreaks. Similarly, the novel method utilizing both modeling frameworks demonstrates its effectiveness in detecting outbreaks of varying sizes.

```{r PODTbl, echo=FALSE}
POD %>%
  filter(k %in% c(2,4,6,8,10)) %>%
  reframe(median(POD), mean(POD),   sd(POD), min(POD), max(POD)) %>%
  kbl(booktabs = TRUE, escape = FALSE, align = "l", longtable = TRUE, caption = "Summary statistics of the \\gls{POD} of an outbreak of size $k$ times the standard deviations of the baseline data for each of the methods applied. ", linesep = c(rep("", 4), "\\addlinespace")) %>%
  kable_paper(latex_options = c("repeat_header", "HOLD_position"), repeat_header_method = c("replace")) %>%
  collapse_rows(columns = 1, 
                latex_hline = "custom",
                valign = "middle",
                custom_latex_hline = 1)
```

In Figure \@ref(fig:PropDetect), the variability in \glspl{POD} of outbreaks can be observed across the 28 scenarios. The level of variability in \gls{POD} is generally low when the outbreak size factor $k$ is set to 1, indicating that only a few outbreaks are detected in these scenarios. Similarly, when $k$ is set to 10, indicating that almost all outbreaks are detected, the variability in \gls{POD} is also low.

On the other hand, the variability in \gls{POD} across the scenarios is highest when $k$ is set to 5, and around $75\%$ of the outbreaks are detected.

(ref:PropDetect) \gls{POD} of an outbreak of a random size $v$ drawn from a Poisson distribution withmean equal to $k$ times the standard deviations of the baseline data. The x-axis shows increasing values of $k$. The \gls{POD} for each scenario is plotted along with the median curves (bold) across all 28 scenarios.

```{r PropDetect, echo=FALSE, out.width="100%", fig.cap="(ref:PropDetect)", fig.pos = "H", fig.show = "hold"}
knitr::include_graphics("../figures/PropDetect.png")
```

It is important to bear in mind that an outbreak of size $v$ is randomly distributed in time according to a discretized log-normal distribution with a mean of $0$ and a standard deviation of $0.5$, denoted as $Z \sim \lfloor \LN(0,0.5^2)\rfloor$. The probability mass function of $Z$ is shown in Figure \@ref(fig:PDFLogNormal). From the figure, it can be observed that $50\%$ of the outbreak cases are added to the same week as the outbreak starts, $42\%$ are added to the following week, and only $7\%$ are added two weeks after the start. Therefore, the simulated outbreak cases are not observed in a single week only but rather in several concurrent weeks.

Consequently, an outbreak of size $v$ generated from a Poisson distribution with a mean equal to $k$ times the standard deviation of the baseline series is perceived to be relatively smaller than initially perceived in the simulation setup. For example, an outbreak of size $k=4$ times the standard deviation may only be perceived as an outbreak signal of size $2$ times the standard deviation in an individual week.


\cleardoublepage
